{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "131d9f4c-1227-40ca-ba72-d8dee0c13403",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "131d9f4c-1227-40ca-ba72-d8dee0c13403",
        "outputId": "418017e9-6f62-4bdb-9892-98b1969eecf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-openai langchain-chroma bs4\n",
        "%pip install -qU langchain-google-vertexai\n",
        "%pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4be099af-ca54-4c0e-9004-9d3b39e591e7",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4be099af-ca54-4c0e-9004-9d3b39e591e7",
        "outputId": "cc46203e-9368-467b-d9a7-ee3d9572932d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "# Import libraries:\n",
        "# I'm following the LangChain documentation here: https://python.langchain.com/v0.2/docs/tutorials/qa_chat_history/\n",
        "\n",
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6719261b-4574-42ea-9dfb-0e6e17945efe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6719261b-4574-42ea-9dfb-0e6e17945efe",
        "outputId": "25f20650-6e58-4623-805d-fa1a93dd5a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "路路路路路路路路路路\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# It will ask for your OpenAI key here\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe592e72-d604-4166-9540-1d7fd4c6593c",
      "metadata": {
        "id": "fe592e72-d604-4166-9540-1d7fd4c6593c"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q2_QI4wgtel0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2_QI4wgtel0",
        "outputId": "525d27d4-cfaa-4bee-ffea-ce362cbd2929"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2af39e-815c-4441-bf12-c996f63606b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe2af39e-815c-4441-bf12-c996f63606b4",
        "outputId": "cb04e410-f5a7-49d7-a0ce-1a8a66343fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "presente-indicativo.pdf\n",
            "ACT.PRESENTE_V. IRREGULARES_CAMBIOS ORTOGRAFICOS.pdf\n",
            "Presente de indicativo.pdf\n",
            "ACT. VERBOS REFLEXIVOS.pdf\n",
            "Verbos REFLEXIVOS y lista de mas comunes.pdf\n",
            "Los verbos reflexivos en espanol.pdf\n"
          ]
        }
      ],
      "source": [
        "# Identical to what we already had:\n",
        "# Read pdfs into the vector database\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# def load_chunk_pdf(path= \"../GenAI/\"):\n",
        "def load_chunk_pdf(path= \"/content/gdrive/MyDrive/Colab Notebooks/Side Hustling \"):\n",
        "    pdf_folder_path = path\n",
        "    documents = []\n",
        "    for file in os.listdir(pdf_folder_path):\n",
        "        if file.endswith('.pdf'):\n",
        "\n",
        "            print (file)\n",
        "            pdf_path = os.path.join(pdf_folder_path, file)\n",
        "            loader = PyPDFLoader(pdf_path)\n",
        "            documents.extend(loader.load())\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
        "    splits = text_splitter.split_documents(documents)\n",
        "    vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
        "\n",
        "    return vectorstore\n",
        "\n",
        "vectorstore = load_chunk_pdf()\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ln3pdWsRyJ6R",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln3pdWsRyJ6R",
        "outputId": "dcbdbb34-faba-4aaa-aa2b-47d2a47222bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.38.1-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting altair<6.0,>=5.0 (from gradio)\n",
            "  Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.111.1)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==1.1.0 (from gradio)\n",
            "  Downloading gradio_client-1.1.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.1.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.1.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=5.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=5.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.0.4)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (2.2.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.22.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=2e71694fd4012f014a14b0d36db093e03a962f8fd6110184342a57219ca46c1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tomlkit, semantic-version, ruff, aiofiles, gradio-client, altair, gradio\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 12.0\n",
            "    Uninstalling websockets-12.0:\n",
            "      Successfully uninstalled websockets-12.0\n",
            "  Attempting uninstall: altair\n",
            "    Found existing installation: altair 4.2.2\n",
            "    Uninstalling altair-4.2.2:\n",
            "      Successfully uninstalled altair-4.2.2\n",
            "Successfully installed aiofiles-23.2.1 altair-5.3.0 ffmpy-0.3.2 gradio-4.38.1 gradio-client-1.1.0 pydub-0.25.1 ruff-0.5.2 semantic-version-2.10.0 tomlkit-0.12.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80869395-5626-4ab9-bc44-154b40db59f5",
      "metadata": {
        "id": "80869395-5626-4ab9-bc44-154b40db59f5"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Here you can fine tune your Prompt.\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are a friendly, witty, and informed professor chatbot. Your name is Uno. You are conversational. Start the conversation by asking them their name and which language they are learning.\"\\\n",
        "    \"You only answer questions regarding Spanish to start. You can help with understanding nuances of Spain's Spanish vs. Latin American Spanish. You specialize in nuances across Spain, Argentina, Mexico, Chile, and Colombia.\"\\\n",
        "    \"If you are asked a question about any other topic or language, you politely explain that you are not able to go beyond Spanish quite yet, but coming soon.\"\\\n",
        "    \"You can help not only with grammar and culturally relevant language, terms, phrases but you also help them understand regionally specific slang.\"\\\n",
        "    \"Give the user in-depth answers, providing some relevant facts, all that are culturally relevant.\"\\\n",
        "     \"Act like a professor - quiz the user, have the user fill in the blank, play learning games back and forth. Be an engaging professor that is actually helping them learn.\"\\\n",
        "    \"Finish your answer checking if whoever asked the question understood the answer or they need more help\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "074c5c00-0ee1-469a-8fb0-e21246583947",
      "metadata": {
        "id": "074c5c00-0ee1-469a-8fb0-e21246583947"
      },
      "outputs": [],
      "source": [
        "## Adding chat history\n",
        "\n",
        "# This allows to make back references to previous questions, so Cass' answers will have \"memory\"\n",
        "\n",
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "contextualize_q_system_prompt = (\n",
        "    \"Given a chat history and the latest user question \"\\\n",
        "    \"which might reference context in the chat history, \"\\\n",
        "    \"formulate a standalone question which can be understood \"\\\n",
        "    \"without the chat history. Do NOT answer the question, \"\\\n",
        "    \"just reformulate it if needed and otherwise return it as is.\"\n",
        ")\n",
        "\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_q_system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "history_aware_retriever = create_history_aware_retriever(\n",
        "    llm, retriever, contextualize_q_prompt\n",
        ")\n",
        "\n",
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
        "\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38c33880-a66f-4615-ad20-5ad6c15efda9",
      "metadata": {
        "id": "38c33880-a66f-4615-ad20-5ad6c15efda9"
      },
      "outputs": [],
      "source": [
        "# Adding conversation sessions to save and continue conversations\n",
        "\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "store = {}\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hfbsZVmSwZlM",
      "metadata": {
        "id": "hfbsZVmSwZlM"
      },
      "outputs": [],
      "source": [
        "# import gradio as gr\n",
        "\n",
        "# gr.ChatInterface(get_llama_response).launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81159273-2bca-4f2b-abd7-f422def53108",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "81159273-2bca-4f2b-abd7-f422def53108",
        "outputId": "411a78fd-8df4-4923-fa58-cbcb73fdcb69"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://cf53463dfde95e7019.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://cf53463dfde95e7019.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# User interface with Gradio\n",
        "# Change debug --> False and comment \"prints\"\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.Button(\"Clear\")\n",
        "    chat_history = []\n",
        "\n",
        "    def user (user_message, history):\n",
        "        #print(\"user\", user)\n",
        "        #print(\"history\", history)\n",
        "        response= conversational_rag_chain.invoke(\n",
        "            {\"input\": user_message},\n",
        "            config={\"configurable\": {\"session_id\": \"Test\"}})\n",
        "        #print(response['answer'])\n",
        "        history.append((user_message, response[\"answer\"]))\n",
        "        #print(\"Updated chat history\", history)\n",
        "        return gr.update(value=\"\"), history\n",
        "\n",
        "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue= False)\n",
        "    clear.click(lambda: None, None, chatbot, queue= False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vpR7te18_ALk",
      "metadata": {
        "id": "vpR7te18_ALk"
      },
      "source": [
        "Building the front end display"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}